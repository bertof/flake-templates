@inproceedings{anisetti_devsecops-based_2022,
	address = {Barcelona, Spain},
	title = {A {DevSecOps}-based {Assurance} {Process} for {Big} {Data} {Analytics}},
	isbn = {978-1-6654-8143-4},
	url = {https://ieeexplore.ieee.org/document/9885738/},
	doi = {10.1109/ICWS55610.2022.00017},
	abstract = {Today big data pipelines are increasingly adopted by service applications representing a key enabler for enterprises to compete in the global market. However, the management of non-functional aspects of the big data pipeline (e.g., security, privacy) is still in its infancy. As a consequence, while functionally appealing, the big data pipeline does not provide a transparent environment, impairing the users{\textquoteright} ability to evaluate its behavior. In this paper, we propose a security assurance methodology for big data pipelines grounded on the DevSecOps development paradigm to increase trustworthiness allowing reliable security and privacy by design. Our methodology models and annotates big data pipelines with non-functional requirements verified by assurance checks ensuring requirements to hold along with the pipeline lifecycle. The performance and quality of our methodology are evaluated in a real walkthrough analytics scenario.},
	language = {en},
	urldate = {2023-06-26},
	booktitle = {2022 {IEEE} {International} {Conference} on {Web} {Services} ({ICWS})},
	publisher = {IEEE},
	author = {Anisetti, Marco and Bena, Nicola and Berto, Filippo and Jeon, Gwanggil},
	month = jul,
	year = {2022},
	keywords = {Assurance, Big Data, Trustworthiness, DevSec-Ops},
	pages = {1--10},
}

@inproceedings{anisetti_qos-aware_2023,
	title = {{QoS}-aware {Deployment} of {Service} {Compositions} in {5G}-empowered {Edge}-{Cloud} {Continuum}},
	shorttitle = {fsgs.dgnsg},
	doi = {10.1109/CLOUD60044.2023.00063},
	abstract = {Nowadays, modern service compositions are increasingly adopted in critical scenarios where advanced Quality of Services (QoS) such as low latency, security, and privacy are fundamental. The landing platforms for the deployment of such compositions are progressively becoming capable to offer capabilities that support such advanced QoS requests (e.g., low latency via 5G network slice) spanning the Edge-Cloud Continuum. Actual deployment solutions focus mainly on resource allocation (i.e., CPU, memory, and storage), falling short of addressing advanced QoS and unleashing the true potential of the Edge-Cloud Continuum. In this paper, we present an automatic QoS-aware deployment solution for composed services in the Edge-Cloud Continuum. It compares QoS requests on the service composition with the capabilities of a given continuum in order to find, generate and execute suitable deployment recipes. Our preliminary experimental evaluation demonstrates the feasibility of our solution in a realistic scenario.},
	booktitle = {2023 {IEEE} {International} {Conference} on {Cloud} {Computing} ({CLOUD})},
	publisher = {IEEE},
	author = {Anisetti, Marco and Berto, Filippo and Bondaruc, Ruslan},
	year = {2023},
	keywords = {5G mobile communication, Quality of service, Security, Cloud computing, Resource management, Privacy, 5G MEC, Edge-Cloud Continuum, Network topology, Non-Functional properties, Service Composition, Service Deployment},
	pages = {471--478},
}

@article{anisetti_security_2022,
	title = {A {Security} {Certification} {Scheme} for {Information}-{Centric} {Networks}},
	volume = {19},
	issn = {1932-4537, 2373-7379},
	url = {https://ieeexplore.ieee.org/document/9750109/},
	doi = {10.1109/TNSM.2022.3165144},
	abstract = {Information-Centric Networking is an emerging alternative to host-centric networking designed for large-scale content distribution and stricter privacy requirements. Recent research on Information-Centric Networking focused on the protection of the network from attacks targeting the content delivery protocols, while assuming genuine content can always be retrieved from trustworthy nodes. In this paper, we depart from the assumption of the trustworthiness of network nodes and propose a novel certification methodology for informationcentric networks that supports continuous security verification of non-functional properties. Our methodology provides a complete and detailed view of the network security status, increasing the trustworthiness of the network and its services. The proposed approach builds on an enhanced certification model capturing the evolution of the system over time. It also defines certification services that fully integrate with existing networks to collect evidence on the target of certification and carry out the certification process. It finally proposes two certification processes, centralized and decentralized, balancing the impact on the network and the system performance. Efficiency, performance, and soundness of our approach are experimentally evaluated in a simulated Named Data Networking (NDN) network targeting property availability.},
	language = {en},
	number = {3},
	urldate = {2023-06-26},
	journal = {IEEE Transactions on Network and Service Management},
	author = {Anisetti, Marco and Ardagna, Claudio A. and Berto, Filippo and Damiani, Ernesto},
	month = sep,
	year = {2022},
	pages = {2397--2408},
}

@phdthesis{berto_assurance-aware_2024,
	address = {Milan},
	title = {{ASSURANCE}-{AWARE} {5G} {EDGE}-{CLOUD} {ARCHITECTURES} {FOR} {INTENSIVE} {DATA} {ANALYTICS}},
	url = {https://hdl.handle.net/2434/1021895},
	abstract = {Modern data-intensive applications are increasingly demanding in terms of non-functional properties such as performance, latency, security, and privacy. In order to achieve such non-functional properties, modern applications benefit from being developed as a composition of services and deployed in a heterogeneous continuum infrastructure that includes Edge and Cloud facilities. In this scenario, the infrastructures used to deploy services play a crucial role in providing or supporting non-functional properties of the applications. For instance, low latency can be achieved via deployment of services in the far edge nodes. Most of the current literature addresses the problem of deployment of single (stateless)services mainly with the aim of ensuring and verifying requirements in terms of resources and performance. Only few solutions exist to deploy applications made of services workflows, and in most of the cases they are focused on functional composition. In general, they fail to address composition deployment preserving advanced non-functional properties such as security and privacy. This thesis proposes novel assurance methodology for modern continuum infrastructures, enabling lightweight in-depth verification and assessment of non-functional properties constituting the key cornerstone for a fully non-functional-aware deployment of service based applications. The thesis proposes an advanced continuum infrastructure, where the 5G MEC is integrated as an Edge node. It also considers a continuum which is empowered with a big data ecosystem of services, where data-intensive analytic workflows can be executed to support critical applications. The assurance methodology defined in the thesis is collaborative and lightweight, and is based on i) transparent collection of evidence representing measurements of relevant continuum states (obtained via monitoring or testing of standard infrastructure-level hooks), ii) aggregation of measurements into metrics and iii) contracts linking metrics to specific non-functional properties. The assurance methodology decouples infrastructure assurance from data processing assurance and application-level assurance. It is the first attempt to suggest that infrastructure and data processing assurance can effectively complement application-level assurance with a limited increase in computational effort while fully applicable in modern continuum infrastructures. The contributions of this thesis are manifold: i) a generic assurance methodology for modern infrastructures ii) a set of specific verticalization of the generic assurance for 5G MEC, Big Data pipelines and CDN networks, iii) a novel notion of continuum empowered by 5G, iv) property aware deployment solution for the continuum integrating assurance controls, v) a complete realization of a continuum infrastructure with simulated 5G nodes and a real data-intensive application for robotic agronomy vi) full experimental evaluation of utility usability and performance. The assurance approaches developed in the thesis have been applied to a real-world scenario through the construction of a complete 5G-enabled Edge-Cloud continuum infrastructure. This was achieved by integrating a 5G network simulator, a MEC deployment infrastructure, a Big Data engine, and a data analysis pipeline platform. This continuum was used to realize a concrete application in the area of IoT-based automated agronomy. Such application is capable of handling the collection, ingestion, analysis and visualization of on-field data. Such complex modern application requires guarantees on a set of advanced non-functional properties that were verified adopting the assurance methodology defined in the thesis. The obtained results demonstrate the utility and usability of the assurance in the context of modern data-intensive application as well as the limited impact in terms of performance obtained thanks to the approach based on infrastructure-level monitoring and lightweight evidence collection.},
	language = {en},
	school = {University of Milan},
	author = {Berto, Filippo},
	month = jan,
	year = {2024},
}

@article{berto_assurance_2024,
	title = {Assurance in {Advanced} {5G} {Edge} {Continuum}},
	volume = {12},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10766569},
	doi = {10.1109/ACCESS.2024.3503437},
	abstract = {The implementation of distributed applications is more frequently achieved through the configuration of service-oriented workflows, which are then deployed within the Edge-Cloud Continuum. This approach facilitates the support of distributed processing pipelines. In this context, there is an increasing demand for solutions that can continuously guarantee the non-functional properties (e.g. security and performance) of such applications. This demand has been boosted by the advent of 5G, where the Continuum is empowered by the ability to involve pervasive 5G Edge Nodes (i.e., Multi-access Edge Computing) and powerful and reliable connectivity links (i.e., network slices). Although capable to support Non-Functional Properties (NFPs) like performance, the current 5G Core Network (CN) is not yet ready to host and execute service workflows nor capable of providing trustworthy guarantees on more advanced NFPs, such as, integrity, security, and robustness. This delay in achieving the full promise of the 5G CN architecture is having a great impact on the capillary diffusion of key technologies such as AI-empowered workflows, which require a fully trusted execution environment to comply with AI regulations such as the AI act. In this paper, we propose an extension of the 5G CN functionalities that supports service workflow deployment and a methodology for the continuous assessment of Non-Functional Properties, beyond simple performance, implemented in a lightweight assurance framework. Our assurance framework is integrated within a 5G simulator to provide a trustworthy 5G CN test-bed and experimentally evaluated in realistic scenarios.},
	urldate = {2024-11-29},
	journal = {IEEE Access},
	author = {Berto, Filippo and Ardagna, Claudio A. and Banzi, Massimo and Anisetti, Marco},
	year = {2024},
	note = {Conference Name: IEEE Access},
	keywords = {5G mobile communication, Monitoring, Quality of service, Computer architecture, Authentication, Cloud computing, Routing, Protocols, quality assurance, Testing, Microservice architectures, 5G edge continuum, cloud computing security, edge cloud computing, edge cloud infrastructures, non-functional assurance},
	pages = {1--1},
}

@inproceedings{berto_spatial_2020,
	address = {New York, NY, USA},
	series = {{SAC} '20},
	title = {Spatial bloom filter in named data networking: a memory efficient solution},
	isbn = {978-1-4503-6866-7},
	shorttitle = {Spatial bloom filter in named data networking},
	url = {https://doi.org/10.1145/3341105.3374074},
	doi = {10.1145/3341105.3374074},
	abstract = {Among the possible future Internet architectures, Information Centric Networking (ICN) is the most promising one and researchers working on the Named Data Networking (NDN) project are putting efforts towards its deployment in a real scenario. To properly handle content names, the different components of an NDN network need efficient and scalable data structures. In this paper, we propose a new data structure to support the NDN forwarding procedure by replacing the current Forwarding Information Base (FIB): the Spatial Bloom Filter (SBF), a probabilistic data structure that guarantees fast lookup and efficient memory consumption. Through a set of simulations run to compare the performance of FIB and SBF, we found that the latter uses less than 5 KB of data to handle 106 queried interests, with a (negligible) probability 10-4 of false positive events. Conversely, the FIB requires up to 2.5 GB of data in disadvantageous cases, e.g. when interests are composed of a considerable number of components.},
	language = {en},
	urldate = {2025-02-17},
	booktitle = {Proceedings of the 35th {Annual} {ACM} {Symposium} on {Applied} {Computing}},
	publisher = {Association for Computing Machinery},
	author = {Berto, Filippo and Calderoni, Luca and Conti, Mauro and Losiouk, Eleonora},
	month = mar,
	year = {2020},
	keywords = {named data networking, information centric networking, spatial bloom filter},
	pages = {274--277},
}

@inproceedings{anisetti_security_2021,
	address = {Chicago, IL, USA},
	title = {Security {Certification} {Scheme} for {Content}-centric {Networks}},
	url = {https://ieeexplore.ieee.org/document/9592454},
	doi = {10.1109/SCC53864.2021.00033},
	abstract = {Content-centric networking is emerging as a credible alternative to host-centric networking, especially in scenarios of large-scale content distribution and where privacy requirements are crucial. Recently, research on content-centric networking has focused on security aspects and proposed solutions aimed to protect the network from attacks targeting the content delivery protocols. Content-centric networks are based on the strong assumption of being able to access genuine content from genuine nodes, which is however unrealistic and could open the door to disruptive attacks. Network node misbehavior, either due to poisoning attacks or malfunctioning, can act as a persistent threat that goes unnoticed and causes dangerous consequences. In this paper, we propose a novel certification methodology for content-centric networks that improves transparency and increases trustworthiness of the network and its nodes. The proposed approach builds on behavioral analysis and implements a continuous certification process that collects evidence from the network nodes and verifies their non-functional properties using a rule-based inference model. Utility, performance, and soundness of our approach have been experimentally evaluated on a simulated Named Data Networking (NDN) network targeting properties availability, integrity, and non-repudiation.},
	language = {english},
	urldate = {2025-02-17},
	booktitle = {2021 {IEEE} {International} {Conference} on {Services} {Computing} ({SCC})},
	publisher = {IEEE},
	author = {Anisetti, Marco and Ardagna, Claudio A. and Berto, Filippo and Damiani, Ernesto},
	month = sep,
	year = {2021},
	note = {ISSN: 2474-2473},
	keywords = {Quality of service, Conferences, Analytical models, named data networking, Protocols, security, certification, Privacy, Information-centric networking, Content-centric networking, Service computing},
	pages = {203--212},
}

@inproceedings{anisetti_orchestration_2022,
	address = {Terassa, Spain},
	title = {Orchestration of data-intensive pipeline in {5G}-enabled {Edge} {Continuum}},
	url = {https://ieeexplore.ieee.org/abstract/document/9860308},
	doi = {10.1109/SERVICES55459.2022.00025},
	abstract = {Nowadays there is an increasing trend in the volume and velocity of data, typically consumed by data-intensive AI/ML-based services, requiring a larger diffusion of more effective Edge computing approaches. In addition, we are experiencing an increment of critical applications using an increasing volume of sensitive data and requiring advanced security and privacy protections. 5G Edge technology can foster a more diffused Edge computing adoption but several challenges in terms of interoperability. Handling data-intensive pipelines on the 5Genabled Edge continuum, considering specific QoS requirements including security and privacy, is still in its infancy. In this paper, we propose an initial solution for deploying a data-intensive pipeline in a 5G-enabled Edge continuum satisfying specific QoS requirements. Our approach is based on a QoS-aware meta orchestration modeling of a given pipeline and an orchestration builder generating deployable Edge-specific orchestrations. In this paper, we also present an initial walkthrough scenario in the context of a wet lab analysis pipeline to be deployed on the 5G-enabled Edge continuum.},
	urldate = {2025-02-17},
	booktitle = {2022 {IEEE} {World} {Congress} on {Services} ({SERVICES})},
	publisher = {IEEE},
	author = {Anisetti, Marco and Berto, Filippo and Banzi, Massimo},
	month = jul,
	year = {2022},
	note = {ISSN: 2642-939X},
	keywords = {5G, 5G mobile communication, Quality of service, Security, Pipelines, Cloud, Data privacy, data-intensive pipeline, Edge, Interoperability, Market research, Orchestration, QoS},
	pages = {2--10},
	annote = {ISSN: 2642-939X},
	annote = {ISSN: 2642-939X},
	annote = {ISSN: 2642-939X},
	annote = {ISSN: 2642-939X},
	annote = {ISSN: 2642-939X},
	annote = {ISSN: 2642-939X},
}

@article{anisetti_assurance_2023,
	title = {An assurance process for {Big} {Data} trustworthiness},
	volume = {146},
	issn = {0167-739X},
	url = {https://www.sciencedirect.com/science/article/pii/S0167739X23001371},
	doi = {10.1016/j.future.2023.04.003},
	abstract = {Modern (industrial) domains are based on large digital ecosystems where huge amounts of data and information need to be collected, shared, and analyzed by multiple actors working within and across organizational boundaries. This data-driven ecosystem poses strong requirements on data management and data analysis, as well as on data protection and system trustworthiness. However, although Big Data has reached its functional maturity and represents a key enabler for enterprises to compete in the global market, the assurance and trustworthiness of Big Data computations (e.g., security, privacy) are still in their infancy. While functionally appealing, Big Data does not provide a transparent environment with clear non-functional properties, impairing the users{\textquoteright} ability to evaluate its behavior and clashing with modern data-privacy regulations. In this paper, we present a novel assurance process for Big Data, which evaluates the Big Data pipelines, and the Big Data ecosystem underneath, to provide a comprehensive measure of their trustworthiness. To the best of our knowledge, this approach is the first attempt to address the general problem of Big Data trustworthiness in an holistic way. We experimentally evaluate our solution in a real Big Data Analytics-as-a-Service environment, first presenting a detailed walkthrough evaluation, and then showing its feasibility and negligible performance overhead (i.e., approx 1~min).},
	urldate = {2025-02-17},
	journal = {Future Generation Computer Systems},
	author = {Anisetti, Marco and Ardagna, Claudio A. and Berto, Filippo},
	month = sep,
	year = {2023},
	keywords = {Monitoring, Security, security, Big Data transparency, Distributed systems, Non-functional assurance, Trustworthiness, Big Data Transparency, Distributed Systems, Non-functional Assurance},
	pages = {34--46},
}

